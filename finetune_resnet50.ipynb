{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dd726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "\n",
    "import random\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d42062",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = kagglehub.dataset_download('ambarish/breakhis')\n",
    "print(f\"Dataset downloaded to: {dataset_path}\")\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    level = root.replace(dataset_path, '').count(os.sep)\n",
    "    indent = ' ' * 4 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    if level < 3:  \n",
    "        for f in files[:5]:  \n",
    "            print(f\"{indent}    {f}\")\n",
    "        if len(files) > 5:\n",
    "            print(f\"{indent}    ... ({len(files) - 5} more files)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb01275",
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_path = os.path.join(dataset_path, 'BreaKHis_v1', 'BreaKHis_v1', 'histology_slides', 'breast', 'benign', 'SOB')\n",
    "malignant_path = os.path.join(dataset_path, 'BreaKHis_v1', 'BreaKHis_v1', 'histology_slides', 'breast', 'malignant', 'SOB')\n",
    "\n",
    "def collect_image_paths(base_path, label):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for subtype in os.listdir(base_path):\n",
    "        subtype_path = os.path.join(base_path, subtype)\n",
    "        if not os.path.isdir(subtype_path):\n",
    "            continue\n",
    "            \n",
    "        for patient in os.listdir(subtype_path):\n",
    "            patient_path = os.path.join(subtype_path, patient)\n",
    "            if not os.path.isdir(patient_path):\n",
    "                continue\n",
    "                \n",
    "            for magnification in ['40X', '100X', '200X', '400X']:\n",
    "                mag_path = os.path.join(patient_path, magnification)\n",
    "                if not os.path.exists(mag_path):\n",
    "                    continue\n",
    "                    \n",
    "                for img_file in os.listdir(mag_path):\n",
    "                    if img_file.endswith('.png'):\n",
    "                        image_paths.append(os.path.join(mag_path, img_file))\n",
    "                        labels.append(label)\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "\n",
    "benign_paths, benign_labels = collect_image_paths(benign_path, 0)\n",
    "malignant_paths, malignant_labels = collect_image_paths(malignant_path, 1)\n",
    "\n",
    "all_image_paths = benign_paths + malignant_paths\n",
    "all_labels = benign_labels + malignant_labels\n",
    "\n",
    "print(f\"Total images: {len(all_image_paths)}\")\n",
    "print(f\"Benign images: {len(benign_paths)}\")\n",
    "print(f\"Malignant images: {len(malignant_paths)}\")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'image_path': all_image_paths,\n",
    "    'label': all_labels\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='label', data=df)\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class (0: Benign, 1: Malignant)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1814d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.2, stratify=train_val_df['label'], random_state=42)\n",
    "\n",
    "print(f\"Training set: {len(train_df)} images\")\n",
    "print(f\"Validation set: {len(val_df)} images\")\n",
    "print(f\"Testing set: {len(test_df)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42efd5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_df['label'] = train_df['label'].astype(str)\n",
    "val_df['label'] = val_df['label'].astype(str)\n",
    "test_df['label'] = test_df['label'].astype(str)\n",
    "\n",
    "def create_generator(dataframe, generator, batch_size=BATCH_SIZE):\n",
    "    return generator.flow_from_dataframe(\n",
    "        dataframe=dataframe,\n",
    "        x_col='image_path',\n",
    "        y_col='label',\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "train_generator = create_generator(train_df, train_datagen)\n",
    "val_generator = create_generator(val_df, val_test_datagen)\n",
    "test_generator = create_generator(test_df, val_test_datagen, batch_size=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b082b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(f\"Number of devices: {strategy.num_replicas_in_sync}\")\n",
    "\n",
    "with strategy.scope():\n",
    "    # Create the base model from pre-trained ResNet50\n",
    "    base_model = ResNet50(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "\n",
    "    # Freeze the base model layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add custom layers on top\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # Create the final model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "    )\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368b5ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'resnet50_breakhis_best.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint, early_stopping, reduce_lr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5306863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (Head only)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.save('resnet50_breakhis_phase1.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c6bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unfreezing layers for fine-tuning...\")\n",
    "for layer in base_model.layers[-30:]:  # Unfreeze the last 30 layers\n",
    "    layer.trainable = True\n",
    "    \n",
    "trainable_count = sum(1 for layer in model.layers if layer.trainable)\n",
    "non_trainable_count = sum(1 for layer in model.layers if not layer.trainable)\n",
    "print(f\"Trainable layers: {trainable_count}\")\n",
    "print(f\"Non-trainable layers: {non_trainable_count}\")\n",
    "\n",
    "# Recompile the model\n",
    "with strategy.scope():\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-5), \n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks for the second phase\n",
    "checkpoint_ft = ModelCheckpoint(\n",
    "    'resnet50_breakhis_finetuned.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping_ft = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr_ft = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks_ft = [checkpoint_ft, early_stopping_ft, reduce_lr_ft]\n",
    "\n",
    "# Continue training with unfrozen layers\n",
    "print(\"Fine-tuning the model with unfrozen layers...\")\n",
    "history_fine_tune = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=30,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator),\n",
    "    callbacks=callbacks_ft,\n",
    "    initial_epoch=history.epoch[-1] + 1  # Continue from where we left off\n",
    ")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save('resnet50_breakhis_final.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ddb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training history\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Phase 1 Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Phase 1 Validation')\n",
    "plt.plot(history_fine_tune.history['accuracy'], label='Phase 2 Train')\n",
    "plt.plot(history_fine_tune.history['val_accuracy'], label='Phase 2 Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Phase 1 Train')\n",
    "plt.plot(history.history['val_loss'], label='Phase 1 Validation')\n",
    "plt.plot(history_fine_tune.history['loss'], label='Phase 2 Train')\n",
    "plt.plot(history_fine_tune.history['val_loss'], label='Phase 2 Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ec045",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"resnet50_breakhis_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "print(\"Model architecture saved to disk\")\n",
    "\n",
    "model.save_weights(\"resnet50_breakhis_weights.weights.h5\")\n",
    "print(\"Model weights saved to disk\")\n",
    "\n",
    "print(\"Training and fine-tuning complete. Check the 'Data' tab to download your models.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "breastcancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
